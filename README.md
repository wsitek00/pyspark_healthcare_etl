# Healthcare Data ETL Pipeline ğŸ¥

## Project Overview
This project implements a scalable **ETL (Extract, Transform, Load)** pipeline using **Apache Spark (PySpark)** to analyze healthcare data. 

The goal was to process a raw dataset of 25,000 patients, clean the data, parse unstructured text (symptoms), and derive business insights such as the most common diseases and symptoms distribution.

## ğŸ— Architecture
The pipeline follows modern Data Engineering best practices:
1.  **Extract:** Ingests raw CSV data with explicit schema enforcement (avoiding `inferSchema` overhead).
2.  **Transform:**
    * Parses complex string columns (symptoms list) into arrays using PySpark functions.
    * Performs Data Quality (DQ) checks to ensure data consistency.
3.  **Analyze:**
    * Uses **PySpark DataFrame API** for array operations (`explode`).
    * Uses **Spark SQL** for complex aggregations (mixing SQL with Python).
4.  **Load:** Saves processed data in **Parquet** format (columnar storage) and business reports in **CSV**.

## ğŸ›  Tech Stack
* **Language:** Python 3.10+
* **Processing Engine:** Apache Spark 3.5.0 (PySpark)
* **Testing:** Pytest (Unit Tests with shared SparkSession fixture)
* **CI/CD:** GitHub Actions (Automated testing on push)
* **Version Control:** Git & GitHub
* **Local Dev Tools:** Pandas & PyArrow (used for local storage optimization)

## ğŸ“‚ Project Structure
```text
pyspark_healthcare_etl/
â”œâ”€â”€ .github/workflows/  # CI/CD pipelines
â”œâ”€â”€ config/             # Configuration files
â”œâ”€â”€ data/               # Local data storage (ignored by Git)
â”‚   â”œâ”€â”€ raw/            # Raw CSV input
â”‚   â””â”€â”€ processed/      # Output Parquet/CSV files
â”œâ”€â”€ src/                # Source Code
â”‚   â”œâ”€â”€ jobs/           # ETL Logic (Extract, Load, Analysis)
â”‚   â”œâ”€â”€ transformations/# Pure business logic (unit-testable)
â”‚   â””â”€â”€ utils/          # SparkSession Factory & Schemas
â”œâ”€â”€ tests/              # Unit Tests
â”œâ”€â”€ main.py             # Pipeline Entry Point
â””â”€â”€ requirements.txt    # Dependencies
